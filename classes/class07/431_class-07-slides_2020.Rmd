---
title: "431 Class 07"
author: "thomaselove.github.io/431"
date: "2020-09-15"
output:
  beamer_presentation:
    theme: "Madrid"
    fonttheme: "structurebold"
    colortheme: "whale"
    fig_height: 5.5
    fig_caption: false
---

```{r set-options, echo=FALSE, cache=FALSE, message = FALSE}
knitr::opts_chunk$set(comment=NA)
options(width = 55)
```

## Today's Data

NHANES data from 2011-12: a sample of 1000 adults.

- Fix a problem with the old `nh3` data I'd built in Classes 5 and 6
- Create `nh3` which solves this problem.
- How should we explore these data before modeling?
  - What can we learn about the center, spread, outliers, and shape of quantitative data?
  - Are these blood pressure data well described by a Normal distribution?
- How might we start to look at Associations between our quantities?
  - Scatterplots, Correlation, Linear Models, Smoothing

## Loading our R Packages

```{r, message = FALSE}
library(NHANES)
library(janitor)
library(knitr)
library(broom)
library(magrittr)
library(patchwork)
library(tidyverse)

theme_set(theme_bw())
```

We'll also load another package later that I'll keep secret for now.

## Creating the `old_nh2` data set (from last week)

```{r}
set.seed(20200908) 

old_nh2 <- NHANES %>%
    filter(SurveyYr == "2011_12") %>%
    select(ID, SurveyYr, Age, Height, Weight, BMI, Pulse,
           SleepHrsNight, BPSysAve, BPDiaAve, Gender, 
           PhysActive, SleepTrouble, Smoke100, 
           Race1, HealthGen, Depressed) %>%
    rename(SleepHours = SleepHrsNight, Sex = Gender,
           SBP = BPSysAve, DBP = BPDiaAve) %>%
    filter(Age > 20 & Age < 80) %>% 
    drop_na() %>% 
    slice_sample(., n = 1000) %>% 
    clean_names() 
```

## But, there's a nuisance...

```{r}
old_nh2 %>% arrange(id) %>% select(id:weight) %>% head(7)
```

## There are duplicate records in NHANES

To make this sample representative of the US, some subjects appear in the sample multiple times. Suppose we want to look only at distinct rows.

```{r}
nh_deduplicated <- NHANES %>%
    filter(SurveyYr == "2011_12") %>%
    select(ID, SurveyYr, Age, Height, Weight, BMI, Pulse,
           SleepHrsNight, BPSysAve, BPDiaAve, Gender, 
           PhysActive, SleepTrouble, Smoke100, 
           Race1, HealthGen, Depressed) %>%
    rename(SleepHours = SleepHrsNight, Sex = Gender,
           SBP = BPSysAve, DBP = BPDiaAve) %>%
    filter(Age > 20 & Age < 80) %>% 
    drop_na() %>%
    distinct() # add this to avoid duplicate rows
```

```{r}
dim(nh_deduplicated)
```

## New version of data, without duplications

```{r}
set.seed(20200914) 

nh3 <- nh_deduplicated %>%
  slice_sample(n = 1000) %>%
  clean_names()
```

## Today's Questions

1. How might we explore the blood pressure data to understand it better? In particular, does a Normal model fit our systolic and diastolic blood pressures well?

2. What is the nature of the association between systolic BP and diastolic BP in these NHANES subjects?

### Today's Variables

Name | Description
------: | ------------------------------------------------
`id` | Identifying code for each subject
`sbp` | Systolic Blood Pressure (mm Hg)
`dbp` | Diastolic Blood Pressure (mm Hg)

# Plotting the `sbp` data to learn about center, spread, outliers, and shape

## Histogram of Systolic BP values from `nh3`

```{r, fig.height = 4}
ggplot(data = nh3, aes(x = sbp)) + 
  geom_histogram(binwidth = 5, 
                 fill = "royalblue", col = "gold") +
  labs(title = "1000 Observed SBP values from nh3")
```


## Violin and Boxplot for `nh3` SBP data

```{r, echo = FALSE, message = FALSE, fig.height = 4}
ggplot(nh3, aes(x = "", y = sbp)) + 
  geom_violin(fill = "lemonchiffon") + 
  geom_boxplot(width = 0.3, outlier.size = 3,
               fill = "royalblue", outlier.color = "royalblue") + 
  coord_flip() + 
  labs(x = "nh3 sample")

mosaic::favstats(~ sbp, data = nh3) %>% 
  kable(digits = 1)
```

# Can we describe these data as being well-approximated by a Normal model?

## What is a Normal Model?

By a Normal model, we mean that the data are assumed to be the result of selecting at random from a probability distribution called the Normal (or Gaussian) distribution, which is characterized by a bell-shaped curve.

- The Normal model is defined by establishing the values of two parameters: the mean and the standard deviation.

### When is it helpful to assume our data follow a Normal model?

- When summarizing the data (especially if we want to interpret the mean and standard deviation)
- When creating inferences about populations from samples (as in a t test, or ANOVA)
- When creating regression models, it will often be important to make distributional assumptions about errors, for instance, that they follow a Normal model.

## Does a Normal model fit our data "well enough"?

We evaluate whether a Normal model fits sufficiently well to our data on the basis of (in order of importance):

1. Graphs (DTDP) are the most important tool we have
  - There are several types of graphs available that are designed to (among other things) help us identify clearly several of the potential problems with assuming Normality.
2. Planned analyses after a Normal model decision is made
  - How serious the problems we see in graphs need to be before we worry about them changes substantially depending on how closely the later analyses we plan to do rely on the assumption of Normality.
3. Numerical Summaries are by far the least important even though they seem "easy-to-use" and "objective".

## Does a Normal model fit well for my data?

The least important approach (even though it is seemingly the most objective) is the calculation of various numerical summaries.

Semi-useful summaries help us understand whether they match up well with the expectations of a normal model:

1. Assessing skewness with $skew_1$ (is the mean close to the median)?
2. Assessing coverage probabilities:
  - In a Normal model, mean $\pm$ 1 standard deviation covers 68% of the data.
  - In a Normal model, mean $\pm$ 2 standard deviations covers 95% of the data.
  - In a Normal model, mean $\pm$ 3 standard deviations covers 99.7% of the data.

## Quantifying skew with a simple $skew_1$ measure

$$
skew_1 = \frac{mean - median}{standard \ deviation}
$$

### Interpreting $skew_1$ (for unimodal data)

- $skew_1 = 0$ if the mean and median are the same
- $skew_1 > 0.2$ indicates fairly substantial right skew
- $skew_1 < -0.2$ indicates fairly substantial left skew


## Measuring skewness in the SBP values: `nh3`?

```{r}
mosaic::favstats(~ sbp, data = nh3)
```
```{r}
nh3 %>% summarize(skew1 = (mean(sbp) - median(sbp))/sd(sbp))
```

What does this suggest?

## Empirical Rule for a Normal Model

If the data followed a Normal distribution, perfectly, then about:

- 68% of the data would fall within 1 standard deviation of the mean
- 95% of the data would fall within 2 standard deviations of the mean
- 99.7% of the data would fall within 3 standard deviations of the mean

Remember that, regardless of the distribution of the data:

- Half of the data will fall below the median, and half above it.
- Half of the data will fall in the Interquartile Range (IQR).

## How many SBPs are within 1 SD of the mean?

```{r}
nh3 %>%
  count(sbp > mean(sbp) - sd(sbp), 
        sbp < mean(sbp) + sd(sbp)) %>%
  kable()
```

How does this compare to the expectation under a Normal model? Remember that there are 1000 observations in `nh3`.

## SBP and the mean $\pm$ 2 standard deviations rule?

The total sample size here is 1000.

```{r}
nh3 %>%
  count(sbp > mean(sbp) - 2*sd(sbp), 
        sbp < mean(sbp) + 2*sd(sbp)) %>%
  kable()
```

How does this compare to the expectation under a Normal model?

## Hypothesis Testing to assess Normality

Don't. Graphical approaches are **far** better than hypothesis tests...

```{r}
nh3 %$% shapiro.test(sbp)
```

The very small *p* value ($2.2 \times 10^{-16}$ should be interpreted by you as meaning zero) indicates that the test finds some indications **against** adopting a Normal model for these data. 

- Exciting, huh? But not actually all that useful, alas.

## Why not test for Normality?

There are multiple hypothesis testing schemes (Kolmogorov-Smirnov, etc.) and each looks for one specific violation of a Normality assumption. None can capture the wide range of issues our brains can envision, and none by itself is great at its job.

- With any sort of reasonable sample size, the test is so poor at detecting non-normality compared to our eyes, that it finds problems we don't care about and ignores problems we do care about.

- And without a reasonable sample size, the test is essentially useless.

Whenever you *can* avoid hypothesis testing and instead actually plot the data, you should plot the data. Sometimes you can't plot (especially with really big data) but the test should be a last resort.


## Can we simulate a Normal model for SBP?

Simulate 1000 observations from a Normal distribution with the same mean and standard deviation as our `nh3` systolic BP values...

```{r}
set.seed(1234567)
sim1 <- tibble( sbp_sim = 
                  rnorm(n = 1000, mean = 121.7, sd = 17.1))

mosaic::favstats(~ sbp_sim, data = sim1) %>% 
  kable(digits = 1)
```

## Comparing Boxplots of `nh3` and simulated SBP

```{r, echo = FALSE, warning = FALSE}
p1 <- ggplot(nh3, aes(x = sbp, y = "")) + 
  geom_violin(fill = "gold") + 
  geom_boxplot(fill = "royalblue", width = 0.3, 
               outlier.color = "royalblue", outlier.size = 3) + 
  scale_x_continuous(limits = c(50, 200), breaks = c(60, 90, 120, 150, 180)) +
  labs(y = "nh3 sample") +
  labs(title = "1000 SBP values from nh3")

p2 <- ggplot(sim1, aes(x = sbp_sim, y = "")) + 
  geom_violin() + 
  geom_boxplot(fill = "turquoise", width = 0.3, 
               outlier.size = 3) + 
  scale_x_continuous(limits = c(50, 200), breaks = c(60, 90, 120, 150, 180)) +
  labs(y = "sbp_sim") +
  labs(title = "1000 Simulated SBP values from Normal model")

p1 / p2
```

- Does a Normal model look appropriate for describing the `nh3` SBP?

## Comparing Histograms of `nh3` and simulated SBP

```{r, echo = FALSE, warning = FALSE}
p1 <- ggplot(data = nh3, aes(x = sbp)) + 
  geom_histogram(binwidth = 5, fill = "royalblue", col = "gold") +
  scale_x_continuous(limits = c(50, 200), breaks = c(60, 90, 120, 150, 180)) +
  labs(title = "1000 Observed SBP values from nh3 (sample mean = 121.7, sd = 17.1)")

p2 <- ggplot(sim1, aes(x = sbp_sim)) +
  geom_histogram(binwidth = 5, fill = "turquoise", col = "black") +
  scale_x_continuous(limits = c(50, 200), breaks = c(60, 90, 120, 150, 180)) +
  labs(title = "1000 Simulated Values from Normal model with mean = 121.7, sd = 17.1")

p1 / p2
```

- Does a Normal model look appropriate for describing the `nh3` SBP?

## Rescale `nh3` SBP histogram as density

Suppose we want to rescale the histogram counts so that the bar areas integrate to 1. This will let us overlay a Normal density onto the results.

```{r, fig.height = 4}
ggplot(nh3, aes(x = sbp)) +
  geom_histogram(aes(y = stat(density)), bins = 20, 
                 fill = "royalblue", col = "white")
```

## Density Function, with Normal superimposed

Now we can draw a Normal density curve on top of the rescaled histogram.

```{r, echo = FALSE}
ggplot(nh3, aes(x = sbp)) +
  geom_histogram(aes(y = stat(density)), bins = 20, 
                 fill = "royalblue", col = "white") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(nh3$sbp), 
                            sd = sd(nh3$sbp)),
                col = "red", lwd = 1.5) +
  labs(title = "SBP density, with Normal model superimposed")
```

## Code for plotting Histogram as Density function

Including the superimposition of a Normal density on top of the histogram.

```{r, eval = FALSE}
ggplot(nh3, aes(x = sbp)) +
  geom_histogram(aes(y = stat(density)), 
                 bins = 20, 
                 fill = "royalblue", col = "white") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(nh3$sbp), 
                            sd = sd(nh3$sbp)),
                col = "red", lwd = 1.5) +
  labs(title = "SBP density, with Normal model superimposed")
```

# Using a Normal Q-Q plot

## Normal Q-Q plot of our simulated data

Remember that these are draws from a Normal distribution, so this is what a sample of 1000 Normally distributed data points should look like.

```{r, echo = FALSE, fig.height = 4.5}
ggplot(sim1, aes(sample = sbp_sim)) +
  geom_qq() + geom_qq_line(col = "blue") + 
  theme(aspect.ratio = 1) +
  labs(title = "Normal Q-Q plot: Simulated SBP")
```

## The Normal Q-Q Plot

Tool to help assess whether the distribution of a single sample is well-modeled by the Normal. 

- Suppose we have N data points in our sample. 
- Normal Q-Q plot will plot N points, on a scatterplot.
  - Y value is the data value
  - X value is the expected value for that point in a Normal distribution
  
Using the Normal distribution with the same mean and SD as our sample, R calculates what the minimum value is expected to be, given a sample of size N, then the next smallest value, and so forth all the way up until the maximum value.

- X value in the Normal Q-Q plot is the value that a Normal distribution would take for that rank in the data set.
- We draw a line through Y = X, and points close to the line therefore match what we'd expect from a Normal distribution.


## How do we create a Normal Q-Q plot?

For our simulated blood pressure data

```{r, eval = FALSE}
ggplot(sim1, aes(sample = sbp_sim)) +
  geom_qq() + # plot the points
  geom_qq_line(col = "blue") + # plot the Y = X line
  theme(aspect.ratio = 1) + # make the plot square
  labs(title = "Normal Q-Q plot: Simulated SBP")
```

## Result, again...

```{r, echo = FALSE}
ggplot(sim1, aes(sample = sbp_sim)) +
  geom_qq() + # plot the points
  geom_qq_line(col = "blue") + # plot the Y = X line
  theme(aspect.ratio = 1) + # make the plot square
  labs(title = "Normal Q-Q plot: Simulated SBP")
```

## Interpreting the Normal Q-Q plot?

The Normal Q-Q plot can help us identify data as well approximated by a Normal distribution, or not, because of:

- skew (including distinguishing between right skew and left skew)
- behavior in the tails (which could be heavy-tailed [more outliers than expected] or light-tailed)

1. Normally distributed data are indicated by close adherence of the points to the diagonal reference line.
2. Skew is indicated by substantial curving (on both ends of the distribution) in the points away from the reference line (if both ends curve up, we have right skew; if both ends curve down, this indicates left skew)
3. An abundance or dearth of outliers (as compared to the expectations of a Normal model) are indicated in the tails of the distribution by an "S" shape or reverse "S" shape in the points.

## Example 1: Data from a Normal Distribution

```{r, echo = FALSE}
set.seed(431)
example1 <- rnorm(n = 500, mean = 100, sd = 10)
sim_study <- tibble(example1)

p1 <- ggplot(sim_study, aes(sample = example1)) +
  geom_qq(col = "dodgerblue") + geom_qq_line(col = "navy") + 
  theme(aspect.ratio = 1) + 
  labs(title = "Normal Q-Q plot: Example 1")

p2 <- ggplot(sim_study, aes(x = example1)) +
  geom_histogram(aes(y = stat(density)), 
                 bins = 10, fill = "dodgerblue", col = "white") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(sim_study$example1), 
                            sd = sd(sim_study$example1)),
                col = "navy", lwd = 1.5) +
  labs(title = "Density Function: Example 1")

p3 <- ggplot(sim_study, aes(x = example1, y = "")) +
  geom_boxplot(fill = "dodgerblue", outlier.color = "dodgerblue") + 
  labs(title = "Boxplot: Example 1", y = "")

p1 + (p2 / p3 + plot_layout(heights = c(4,1)))

mosaic::favstats(~ example1, data = sim_study) %>% kable(digits = 1)
```

## Does a Normal model fit well for my data?

1. Is a Normal Q-Q plot showing something close to a straight line, without clear signs of skew or indications of lots of outliers (heavy-tailedness)?

2. Does a boxplot, violin plot and/or histogram also show a symmetric distribution, where both the number of outliers is modest, and the distance of those outliers from the mean is modest?

3. Do numerical measures match up with the expectations of a normal model?

## Example 2: Data from a Left-Skewed Distribution

```{r, echo = FALSE}
set.seed(431)
sim_study$example2 <- rbeta(n = 500, shape = 2, shape2 = 5, ncp = 100)

p1 <- ggplot(sim_study, aes(sample = example2)) +
  geom_qq(col = "dodgerblue") + geom_qq_line(col = "navy") + 
  theme(aspect.ratio = 1) + 
  labs(title = "Normal Q-Q plot: Example 2")

p2 <- ggplot(sim_study, aes(x = example2)) +
  geom_histogram(aes(y = stat(density)), 
                 bins = 10, fill = "dodgerblue", col = "white") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(sim_study$example2), 
                            sd = sd(sim_study$example2)),
                col = "navy", lwd = 1.5) +
  labs(title = "Density Function: Example 2")

p3 <- ggplot(sim_study, aes(x = example2, y = "")) +
  geom_boxplot(fill = "dodgerblue", outlier.color = "dodgerblue") + 
  labs(title = "Boxplot: Example 2", y = "")

p1 + (p2 / p3 + plot_layout(heights = c(4,1)))

mosaic::favstats(~ example2, data = sim_study) %>% kable(digits = 1)
```

## Example 3: Data from a Right-Skewed Distribution

```{r, echo = FALSE}
set.seed(431)
sim_study$example3 <- exp(rnorm(n = 500, mean = 1, sd = 0.5))

p1 <- ggplot(sim_study, aes(sample = example3)) +
  geom_qq(col = "dodgerblue") + geom_qq_line(col = "navy") + 
  theme(aspect.ratio = 1) + 
  labs(title = "Normal Q-Q plot: Example 3")

p2 <- ggplot(sim_study, aes(x = example3)) +
  geom_histogram(aes(y = stat(density)), 
                 bins = 10, fill = "dodgerblue", col = "white") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(sim_study$example3), 
                            sd = sd(sim_study$example3)),
                col = "navy", lwd = 1.5) +
  labs(title = "Density Function: Example 3")

p3 <- ggplot(sim_study, aes(x = example3, y = "")) +
  geom_boxplot(fill = "dodgerblue", outlier.color = "dodgerblue") + 
  labs(title = "Boxplot: Example 3", y = "")

p1 + (p2 / p3 + plot_layout(heights = c(4,1)))

mosaic::favstats(~ example3, data = sim_study) %>% kable(digits = 1)
```

## Example 4: Discrete "Symmetric" Distribution

```{r, echo = FALSE}
set.seed(431)
sim_study$example4 <- rpois(n = 500, lambda = 8)

p1 <- ggplot(sim_study, aes(sample = example4)) +
  geom_qq(col = "dodgerblue") + geom_qq_line(col = "navy") + 
  theme(aspect.ratio = 1) + 
  labs(title = "Normal Q-Q plot: Example 4")

p2 <- ggplot(sim_study, aes(x = example4)) +
  geom_histogram(aes(y = stat(density)), 
                 bins = 10, fill = "dodgerblue", col = "white") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(sim_study$example4), 
                            sd = sd(sim_study$example4)),
                col = "navy", lwd = 1.5) +
  labs(title = "Density Function: Example 4")

p3 <- ggplot(sim_study, aes(x = example4, y = "")) +
  geom_boxplot(fill = "dodgerblue", outlier.color = "dodgerblue") + 
  labs(title = "Boxplot: Example 4", y = "")

p1 + (p2 / p3 + plot_layout(heights = c(4,1)))

mosaic::favstats(~ example4, data = sim_study) %>% kable(digits = 1)
```

## Example 5: Data from a Uniform Distribution

```{r, echo = FALSE, warning = FALSE}
set.seed(431)
sim_study$example5 <- runif(n = 500, min = 0, max = 100)

p1 <- ggplot(sim_study, aes(sample = example5)) +
  geom_qq(col = "dodgerblue") + geom_qq_line(col = "navy") + 
  theme(aspect.ratio = 1) + 
  labs(title = "Normal Q-Q plot: Example 5")

p2 <- ggplot(sim_study, aes(x = example5)) +
  geom_histogram(aes(y = stat(density)), 
                 bins = 10, fill = "dodgerblue", col = "white") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(sim_study$example5), 
                            sd = sd(sim_study$example5)),
                col = "navy", lwd = 1.5) +
  scale_x_continuous(limits = c(0, 100)) +
  labs(title = "Density Function: Example 5")

p3 <- ggplot(sim_study, aes(x = example5, y = "")) +
  geom_boxplot(fill = "dodgerblue", outlier.color = "dodgerblue") + 
  labs(title = "Boxplot: Example 5", y = "")

p1 + (p2 / p3 + plot_layout(heights = c(4,1)))

mosaic::favstats(~ example5, data = sim_study) %>% kable(digits = 1)
```

## Example 6: Symmetric data with outliers

```{r, echo = FALSE, message = FALSE}
set.seed(431)
sim_study$example6 <- rnorm(n = 500, mean = 50, sd = 10)
sim_study$example6[14] <- 5
sim_study$example6[15] <- 3
sim_study$example6[39] <- 93
sim_study$example6[38] <- 97

p1 <- ggplot(sim_study, aes(sample = example6)) +
  geom_qq(col = "dodgerblue") + geom_qq_line(col = "navy") + 
  theme(aspect.ratio = 1) + 
  labs(title = "Normal Q-Q plot: Example 6")

p2 <- ggplot(sim_study, aes(x = example6)) +
  geom_histogram(aes(y = stat(density)), 
                 bins = 10, fill = "dodgerblue", col = "white") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(sim_study$example6), 
                            sd = sd(sim_study$example6)),
                col = "navy", lwd = 1.5) +
  labs(title = "Density Function: Example 6")

p3 <- ggplot(sim_study, aes(x = example6, y = "")) +
  geom_boxplot(fill = "dodgerblue", outlier.color = "dodgerblue") + 
  labs(title = "Boxplot: Example 6", y = "")

p1 + (p2 / p3 + plot_layout(heights = c(4,1)))

mosaic::favstats(~ example6, data = sim_study) %>% kable(digits = 1)
```

## Our 1000 simulated Systolic Blood Pressures

```{r, echo = FALSE}
p1 <- ggplot(sim1, aes(sample = sbp_sim)) +
  geom_qq(col = "turquoise") + geom_qq_line(col = "black") + 
  theme(aspect.ratio = 1) + 
  labs(title = "Normal Q-Q plot: sbp_sim")

p2 <- ggplot(sim1, aes(x = sbp_sim)) +
  geom_histogram(aes(y = stat(density)), 
                 bins = 20, fill = "turquoise", col = "white") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(sim1$sbp_sim), 
                            sd = sd(sim1$sbp_sim)),
                col = "black", lwd = 1.5) +
  labs(title = "Density Function: sbp_sim")

p3 <- ggplot(sim1, aes(x = sbp_sim, y = "")) +
  geom_boxplot(fill = "turquoise", outlier.color = "black") + 
  labs(title = "Boxplot: sbp_sim", y = "")

p1 + (p2 / p3 + plot_layout(heights = c(4,1)))

mosaic::favstats(~ sbp_sim, data = sim1) %>% kable(digits = 1)
```

## A Normal Q-Q Plot of the nh3 SBP data (n = 1000)

```{r, echo = FALSE}
ggplot(nh3, aes(sample = sbp)) +
  geom_qq() + geom_qq_line(col = "red") + 
  theme(aspect.ratio = 1) + 
  labs(title = "Normal Q-Q plot of nh3 SBP")
```

## Our 1000 observed Systolic Blood Pressures

```{r, echo = FALSE}
p1 <- ggplot(nh3, aes(sample = sbp)) +
  geom_qq(col = "royalblue") + geom_qq_line(col = "red") + 
  theme(aspect.ratio = 1) + 
  labs(title = "Normal Q-Q plot: nh3 SBP")

p2 <- ggplot(nh3, aes(x = sbp)) +
  geom_histogram(aes(y = stat(density)), 
                 bins = 20, fill = "royalblue", col = "gold") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(nh3$sbp), 
                            sd = sd(nh3$sbp)),
                col = "red", lwd = 1.5) +
  labs(title = "Density Function: nh3 SBP")

p3 <- ggplot(nh3, aes(x = sbp, y = "")) +
  geom_boxplot(fill = "royalblue", outlier.color = "royalblue") + 
  labs(title = "Boxplot: nh3 SBP", y = "")

p1 + (p2 / p3 + plot_layout(heights = c(4,1)))

mosaic::favstats(~ sbp, data = nh3) %>% kable(digits = 1)
```


## More Extensive Numerical Summaries?

We could try

```
nh3 %>% Hmisc::describe(sbp)
```

>- but that will throw an error message, specifically `Error in describe.data.frame(., sbp) : object 'sbp' not found`. What is wrong? How can we fix that?

>- We could drop the pipe and use `$` notation, so `Hmisc::describe(nh3$sbp)`

>- Another option is to change the pipe (to the `%$%` pipe available in the `magrittr` package): `nh3 %$% Hmisc::describe(sbp)`

## What do these summaries tell us?

```{r}
nh3 %$% Hmisc::describe(sbp)
```

- `Gmd` = Gini's mean difference (a robust measure of spread) = mean absolute difference between any pairs of observations. Larger `Gmd` indicates more spread.
- `Info` = a measure of relative information describing how "continuous" the data are. Higher `Info` indicates fewer ties.

## What Summaries to Report

It is usually helpful to focus on the shape, center and spread of a distribution. Bock, Velleman and DeVeaux provide some useful advice:

- If the data are skewed, report the median and IQR (or the three middle quantiles). You may want to include the mean and standard deviation, but you should point out why the mean and median differ. The fact that the mean and median do not agree is a sign that the distribution may be skewed. A histogram will help you make that point.

- If the data are symmetric, report the mean and standard deviation, and possibly the median and IQR as well.

- If there are clear outliers and you are reporting the mean and standard deviation, report them with the outliers present and with the outliers removed. The differences may be revealing. The median and IQR are not likely to be seriously affected by outliers.

## OK, what about Diastolic Blood Pressure?

```{r, fig.height = 4.5}
ggplot(data = nh3, aes(x = dbp)) + 
  geom_histogram(bins = 20, fill = "tomato", col = "gold")
```

- We can generate the set of plots we've been using...

## DBP in nh3: Center/Spread/Outliers/Shape?

```{r, echo = FALSE}
p1 <- ggplot(nh3, aes(sample = dbp)) +
  geom_qq(col = "tomato") + geom_qq_line(col = "black") + 
  theme(aspect.ratio = 1) + 
  labs(title = "Normal Q-Q plot: nh3 DBP")

p2 <- ggplot(nh3, aes(x = dbp)) +
  geom_histogram(aes(y = stat(density)), 
                 bins = 20, fill = "tomato", col = "gold") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(nh3$dbp), 
                            sd = sd(nh3$dbp)),
                col = "black", lwd = 1.5) +
  labs(title = "Density Function: nh3 DBP")

p3 <- ggplot(nh3, aes(x = dbp, y = "")) +
  geom_boxplot(fill = "tomato", outlier.color = "tomato") + 
  labs(title = "Boxplot: nh3 DBP", y = "")

p1 + (p2 / p3 + plot_layout(heights = c(4,1)))

mosaic::favstats(~ dbp, data = nh3) %>% kable(digits = 1)
```

## Does a Normal model fit well for my data?

1. Is a Normal Q-Q plot showing something close to a straight line, without clear signs of skew or indications of lots of outliers (heavy-tailedness)?
2. Does a boxplot, violin plot and/or histogram also show a symmetric distribution, where both the number of outliers is modest, and the distance of those outliers from the mean is modest?
3. Do numerical measures match up with the expectations of a normal model?

## Hmisc::describe for `dbp`?

```{r}
nh3 %$% Hmisc::describe(dbp)
```

What is a plausible diastolic blood pressure?

## Stem-and-Leaf of `dbp` values?

```{r}
stem(nh3$dbp)
```

## Who are those people with tiny `dbp` values?

```{r}
nh3 %>%
  filter(dbp < 40) %>% 
  select(id, sbp, dbp)
```

## Let's reset.

```{r}
nh3_new <- nh3 %>%
  filter(dbp > 39)

nrow(nh3)
nrow(nh3_new)
```

We'll work with `nh3_new` for the rest of today. 

## nh3_new: Systolic Blood Pressure

```{r, echo = FALSE}
p1 <- ggplot(nh3_new, aes(sample = sbp)) +
  geom_qq(col = "royalblue") + geom_qq_line(col = "red") + 
  theme(aspect.ratio = 1) + 
  labs(title = "Normal Q-Q plot: nh3 SBP")

p2 <- ggplot(nh3, aes(x = sbp)) +
  geom_histogram(aes(y = stat(density)), 
                 bins = 20, fill = "royalblue", col = "gold") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(nh3$sbp), 
                            sd = sd(nh3$sbp)),
                col = "red", lwd = 1.5) +
  labs(title = "Density Function: nh3 SBP")

p3 <- ggplot(nh3, aes(x = sbp, y = "")) +
  geom_boxplot(fill = "royalblue", outlier.color = "royalblue") + 
  labs(title = "Boxplot: nh3 SBP", y = "")

p1 + (p2 / p3 + plot_layout(heights = c(4,1)))

mosaic::favstats(~ sbp, data = nh3) %>% kable(digits = 1)
```

## nh3_new: Diastolic Blood Pressure

```{r, echo = FALSE}
p1 <- ggplot(nh3_new, aes(sample = dbp)) +
  geom_qq(col = "tomato") + geom_qq_line(col = "black") + 
  theme(aspect.ratio = 1) + 
  labs(title = "Normal Q-Q plot: nh3 DBP")

p2 <- ggplot(nh3, aes(x = dbp)) +
  geom_histogram(aes(y = stat(density)), 
                 bins = 20, fill = "tomato", col = "gold") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(nh3$dbp), 
                            sd = sd(nh3$dbp)),
                col = "black", lwd = 1.5) +
  labs(title = "Density Function: nh3 DBP")

p3 <- ggplot(nh3, aes(x = sbp, y = "")) +
  geom_boxplot(fill = "tomato", outlier.color = "tomato") + 
  labs(title = "Boxplot: nh3 DBP", y = "")

p1 + (p2 / p3 + plot_layout(heights = c(4,1)))

mosaic::favstats(~ dbp, data = nh3) %>% kable(digits = 1)
```

## Summing Up: Does a Normal Model fit well?

If a Normal model fits our data well, then we should see the following graphical indications:

1. A histogram that is symmetric and bell-shaped.
2. A boxplot where the box is symmetric around the median, as are the whiskers, without a serious outlier problem.
3. A normal Q-Q plot that essentially falls on a straight line.

As for numerical summaries, we'd like to see

4. The mean and median within 0.2 standard deviation of each other.
5. No real evidence of too many outlier candidates (more than 5% starts to get us concerned about a Normal model)
6. No real evidence of individual outliers outside the reasonable range for the size of our data (we might expect about 3 observations in 1000 to fall more than 3 standard deviations away from the mean.)

# How can we describe the relationship between SBP and DBP? 

## Scatterplot to study the SBP-DBP association

```{r, fig.height = 4.5}
ggplot(nh3_new, aes(x = dbp, y = sbp)) +
  geom_point(col = "purple") + 
  theme(aspect.ratio = 1) # make the plot square for slide
```

## Try to predict `sbp` from `dbp`?

```{r, fig.height = 4.5}
ggplot(nh3_new, aes(x = dbp, y = sbp)) + 
  geom_point(col = "purple") + theme(aspect.ratio = 1) +
  geom_smooth(method = "lm", formula = y ~ x, 
              col = "red", se = TRUE)
```

## What should we conclude from this scatterplot?

1. Each of the 989 subjects in `nh3_new` is represented by one of the points.
2. The association appears generally to be "positive" or "direct" in that as `dbp` increases, so does `sbp`.
3. The association appears fairly linear, in that most of the points cluster around a pattern fit well by a straight line.
4. The association is not particularly strong in that the range of `sbp` values associated with any particular `dbp` value is still pretty wide. 
  - If we know someone's `dbp`, that should help us make better predictions of their sbp, but perhaps not much better than if we didn't know their `dbp`.
5. I don't see any substantial outliers that are far away from all other points.

## What line is being fit there?

Least Squares Regression Line (a linear model) to predict `sbp` using `dbp`

```{r}
m1 <- lm(sbp ~ dbp, data = nh3_new)
m1
```

Model m1 is **sbp = 76.13 + 0.62 dbp**. 

- What do the slope and intercept mean?

## Linear Model `m1`: sbp = 76.13 + 0.62 dbp

76.13 is the intercept = predicted value of `sbp` when `dbp` = 0.

- Is that reasonable in this setting?

0.62 is the slope = predicted change in `sbp` per 1 unit change in `dbp`

- What are the units here?
- What does the fact that this estimated slope is positive mean?
- What would the line look like if the slope was negative? What if the slope was zero?


## Does R like this linear model?

```{r}
tidy(m1) %>% kable(digits = 2)
```

Yes. Wow. It **really** does. Look at those *p* values!

## Does a linear model really work well here?

```{r, fig.height = 4.5}
ggplot(nh3_new, aes(x = dbp, y = sbp)) + 
  geom_point() + theme(aspect.ratio = 1) +
  geom_smooth(method = "loess", formula = y ~ x, 
              col = "blue", se = TRUE)
```

Hmmm...

## How much of the variation in `sbp` does m1 capture?

```{r}
glance(m1) %>% select(r.squared, sigma, p.value) 
```

## Who can we make predictions for using model m1?

We sampled 1000 observations from a group, and then dropped those with `dbp` below 40, leaving n = 989.) How many people in total would be eligible?

```{r}
nh3_eligible <- nh_deduplicated %>%
  clean_names() %>%
  filter(dbp > 39) 

dim(nh3_eligible)
dim(nh3_new)
```

## Can we look at the other (1709 - 989 = 720) subjects?

```{r}
nh3_therest <- anti_join(nh3_eligible, nh3_new, by = "id")

dim(nh3_therest)
```

## Can we use m1 to predict SBP in our `nh3_therest` data?

```{r}
new720_nh3 <- augment(m1, newdata = nh3_therest)

new720_nh3 %>% select(id, sbp, dbp, .fitted, .resid) %>% 
  head() %>% kable(digits = 2)
```

## Out of Sample: Actual SBP vs. Fitted SBP by `m1` (n = 720)

```{r, fig.height = 4.5}
ggplot(new720_nh3, aes(x = .fitted, y = sbp)) +
  geom_abline(slope = 1, intercept = 0, col = "red") +
  geom_point() + theme(aspect.ratio = 1) 
```

## Out of Sample: Residuals vs. Fitted SBP by `m1` (n = 720)

```{r, fig.height = 4.5}
ggplot(new720_nh3, aes(x = .fitted, y = .resid)) +
  geom_point() + theme(aspect.ratio = 1) +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE)
```


## Numerical Summary: Pearson Correlation

The Pearson correlation ranges from -1 to +1.

- The closer the absolute value of the correlation is to 1, the stronger a linear fit will be to the data, (in a limited sense).
- A strong positive correlation (near +1) will indicate a strong model with a positive slope.
- A strong negative correlation (near -1) will indicate a strong linear model with a negative slope.
- A weak correlation (near 0) will indicate a poor fit for a linear model, although a non-linear model may still fit the data quite well.

## Correlation in our sbp-dbp scatterplot?

```{r, fig.height = 3}
ggplot(nh3_new, aes(x = dbp, y = sbp)) +
  geom_point() + theme(aspect.ratio = 1)

nh3_new %$% cor(sbp, dbp)
```

What does a correlation of +0.53 imply about a linear fit to the data?

## How is the r-squared ($r^2$)?

```{r}
glance(m1) %>% select(r.squared) %>% kable()
```

- R-squared describes the proportion of the variation in `sbp` accounted for by the linear model `m1` using `dbp`. 
- About 28% in this case. Is that good?
- Why is this called R-squared? What is the R?

```{r}
nh3_new %$% cor(sbp, dbp)
```

```{r}
nh3_new %$% cor(sbp, dbp)^2
```


## Is this the only linear model R can fit to these data?

Nope.

```{r}
library(rstanarm)
```

## Fit linear model using `stan_glm`?

```{r}
m2 <- stan_glm(sbp ~ dbp, data = nh3_new)
```

## Bayesian fitted linear model for our sbp data

```{r}
print(m2)
```

## Is the Bayesian model (with default prior) very different from our `lm` in this situation?

```{r}
coef(m1) # fit with lm

coef(m2) # stan_glm with default priors
```


## How about a robust linear model?

```{r}
# requires installation of robust package
# which I doubt we'll use again

m3 <- robust::lmRob(sbp ~ dbp, data = nh3_new)

tidy(m3) %>% kable(digits = 3)
```

## Or another kind of robust linear model?

```{r}
# requires installation of robustbase package
# which I doubt we'll ever use again

m4 <- robustbase::lmrob(sbp ~ dbp, data = nh3_new)

tidy(m4) %>% kable(digits = 3)
```


